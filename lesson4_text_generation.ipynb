{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LESSON 4: TEXT GENERATION METRICS üåç\n",
    "*Grading AI writers - BLEU & ROUGE explained*\n",
    "\n",
    "## What You'll Learn\n",
    "- **BLEU** - For translation (is your translator lying?)\n",
    "- **ROUGE** - For summarization (did you skip the important parts?)\n",
    "- **N-grams** - Why order matters (\"dog bites man\" ‚â† \"man bites dog\")\n",
    "- **When to use what** - Translation vs Summarization\n",
    "\n",
    "## Real Talk\n",
    "When AI generates text, how do we know if it's good? You can't just count \"correct\" like classification.\n",
    "\n",
    "**The problem:** There are infinite correct ways to say the same thing!\n",
    "- \"The cat sat\" vs \"A cat was sitting\" vs \"There was a cat, and it sat\"\n",
    "\n",
    "All correct! So how do we grade this? Enter BLEU and ROUGE - the metrics that compare your AI's output to human references.\n",
    "\n",
    "**Spoiler:** They're not perfect (they don't understand meaning), but they're what we got! ü§∑\n",
    "\n",
    "Let's dive in! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking/installing packages...\n",
      "‚úì All packages ready!\n",
      "\n",
      "üåç Text Generation Evaluation Notebook Loaded!\n",
      "We'll learn BLEU (translation) and ROUGE (summarization)!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run this first!)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['nltk', 'rouge-score', 'numpy', 'matplotlib']\n",
    "print(\"Checking/installing packages...\")\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "print(\"‚úì All packages ready!\\n\")\n",
    "\n",
    "# Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK data\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "print(\"üåç Text Generation Evaluation Notebook Loaded!\")\n",
    "print(\"We'll learn BLEU (translation) and ROUGE (summarization)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 1: BLEU Score üåç\n",
    "*For translation - counts matching word chunks (n-grams)*\n",
    "\n",
    "### What is it?\n",
    "**BLEU** = Bilingual Evaluation Understudy (fancy name for \"do the words match?\")\n",
    "\n",
    "It counts how many **n-grams** (word sequences) match between:\n",
    "- Your AI's translation\n",
    "- A human reference translation\n",
    "\n",
    "**What's an \"n-gram\"?** A sequence of n consecutive words:\n",
    "- 1-gram (unigram): single word [\"cat\"]\n",
    "- 2-gram (bigram): two words [\"the cat\"]  \n",
    "- 3-gram (trigram): three words [\"the cat sat\"]\n",
    "\n",
    "### The Metaphor\n",
    "Imagine translating English ‚Üí Spanish. BLEU is like a teacher who:\n",
    "1. Checks if you used the right words ‚úì\n",
    "2. Checks if you put them in the right order ‚úì\n",
    "3. Doesn't care if you understood the meaning ‚úó\n",
    "\n",
    "**Example:**\n",
    "- Reference: \"The cat sat on the mat\"\n",
    "- Your AI: \"Cat mat on sat the\" ‚Üê All the right words, WRONG order!\n",
    "- BLEU: \"Yo this is trash\" (low score)\n",
    "\n",
    "### Why BLEU has limitations (but is still widely used)\n",
    "- Uses \"quick\" and \"fast\"? BLEU thinks they're different words ü§¶\n",
    "- Synonyms? BLEU doesn't know what those are\n",
    "- Different sentence structure but same meaning? Penalized!\n",
    "\n",
    "But hey, it's fast and works well enough for most cases!\n",
    "\n",
    "Let's see it in action..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç BLEU SCORE - For Translation Quality\n",
      "============================================================\n",
      "BLEU = Bi-Lingual Evaluation Understudy\n",
      "Measures how similar generated text is to reference\n",
      "\n",
      "Reference translation: 'the cat sat on the mat'\n",
      "\n",
      "Perfect match                  ‚Üí BLEU: 1.000 üî•\n",
      "  Generated: 'The cat sat on the mat'\n",
      "  Matching words: {'sat', 'on', 'mat', 'cat', 'the'}\n",
      "\n",
      "Good (minor difference)        ‚Üí BLEU: 0.000 üí©\n",
      "  Generated: 'The cat is on the mat'\n",
      "  Matching words: {'on', 'mat', 'the', 'cat'}\n",
      "\n",
      "Okay (different articles)      ‚Üí BLEU: 0.000 üí©\n",
      "  Generated: 'A cat sat on a mat'\n",
      "  Matching words: {'sat', 'on', 'mat', 'cat'}\n",
      "\n",
      "Bad (wrong order)              ‚Üí BLEU: 0.000 üí©\n",
      "  Generated: 'Cat mat on sat the'\n",
      "  Matching words: {'sat', 'on', 'mat', 'cat', 'the'}\n",
      "\n",
      "Terrible (different meaning)   ‚Üí BLEU: 0.000 üí©\n",
      "  Generated: 'The dog stood near the chair'\n",
      "  Matching words: {'the'}\n",
      "\n",
      "üí° BLEU Score range: 0.0 to 1.0 (higher = better)\n",
      "   0.5+ = Good translation\n",
      "   0.3-0.5 = Decent\n",
      "   <0.3 = Needs work\n"
     ]
    }
   ],
   "source": [
    "print(\"üåç BLEU SCORE - For Translation Quality\")\n",
    "print(\"=\"*60)\n",
    "print(\"BLEU = Bi-Lingual Evaluation Understudy\")\n",
    "print(\"Measures how similar generated text is to reference\")\n",
    "print()\n",
    "\n",
    "# Reference (correct translation)\n",
    "reference = \"The cat sat on the mat\".lower().split()\n",
    "\n",
    "# Different quality translations\n",
    "translations = [\n",
    "    (\"The cat sat on the mat\", \"Perfect match\"),\n",
    "    (\"The cat is on the mat\", \"Good (minor difference)\"),\n",
    "    (\"A cat sat on a mat\", \"Okay (different articles)\"),\n",
    "    (\"Cat mat on sat the\", \"Bad (wrong order)\"),\n",
    "    (\"The dog stood near the chair\", \"Terrible (different meaning)\")\n",
    "]\n",
    "\n",
    "print(f\"Reference translation: '{' '.join(reference)}'\\n\")\n",
    "\n",
    "for trans_text, description in translations:\n",
    "    candidate = trans_text.lower().split()\n",
    "    \n",
    "    # Calculate BLEU\n",
    "    bleu = sentence_bleu([reference], candidate)\n",
    "    \n",
    "    # Rating\n",
    "    if bleu > 0.8:\n",
    "        rating = \"üî•\"\n",
    "    elif bleu > 0.5:\n",
    "        rating = \"üëç\"\n",
    "    elif bleu > 0.3:\n",
    "        rating = \"üòê\"\n",
    "    else:\n",
    "        rating = \"üí©\"\n",
    "    \n",
    "    print(f\"{description:30s} ‚Üí BLEU: {bleu:.3f} {rating}\")\n",
    "    print(f\"  Generated: '{trans_text}'\")\n",
    "    \n",
    "    # Show matching words\n",
    "    matches = set(reference) & set(candidate)\n",
    "    print(f\"  Matching words: {matches}\\n\")\n",
    "\n",
    "print(\"üí° BLEU Score range: 0.0 to 1.0 (higher = better)\")\n",
    "print(\"   0.5+ = Good translation\")\n",
    "print(\"   0.3-0.5 = Decent\")\n",
    "print(\"   <0.3 = Needs work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 2: N-grams Deep Dive\n",
    "*Why \"dog bites man\" ‚â† \"man bites dog\"*\n",
    "\n",
    "### What are n-grams?\n",
    "- **1-gram (unigram):** Individual words [\"the\", \"cat\", \"sat\"]\n",
    "- **2-gram (bigram):** Word pairs [\"the cat\", \"cat sat\"]\n",
    "- **3-gram (trigram):** Word triples [\"the cat sat\"]\n",
    "- **4-gram:** You get the idea...\n",
    "\n",
    "### Why n-grams matter\n",
    "Just matching individual words isn't enough!\n",
    "\n",
    "**Example:**\n",
    "- Reference: \"The dog bit the man\"\n",
    "- Translation 1: \"The man bit the dog\" ‚Üê Same words, OPPOSITE meaning!\n",
    "- Translation 2: \"The dog bit the man\" ‚Üê Perfect!\n",
    "\n",
    "**1-gram matching alone:** Both get 100%! (all words match)  \n",
    "**2-gram matching:** Translation 1 fails! (\"dog bit\" vs \"man bit\")\n",
    "\n",
    "This is why BLEU checks multiple n-gram sizes!\n",
    "\n",
    "Let's see the math..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BLEU BREAKDOWN\n",
      "============================================================\n",
      "Reference:  the quick brown fox jumps over the lazy dog\n",
      "Generated:  the fast brown fox leaps over the lazy dog\n",
      "\n",
      "n-gram precision:\n",
      "  1-gram: 7/9 = 77.8%\n",
      "  2-gram: 4/8 = 50.0%\n",
      "  3-gram: 2/7 = 28.6%\n",
      "  4-gram: 1/6 = 16.7%\n",
      "\n",
      "Overall BLEU: 0.369\n",
      "\n",
      "What changed:\n",
      "  'quick' ‚Üí 'fast' (synonym, but BLEU doesn't know that!)\n",
      "  'jumps' ‚Üí 'leaps' (synonym, but BLEU penalizes it)\n",
      "\n",
      "üí° BLEU limitation: Doesn't understand synonyms or meaning!\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from collections import Counter\n",
    "\n",
    "reference = \"the quick brown fox jumps over the lazy dog\".split()\n",
    "candidate = \"the fast brown fox leaps over the lazy dog\".split()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BLEU BREAKDOWN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Reference:  {' '.join(reference)}\")\n",
    "print(f\"Generated:  {' '.join(candidate)}\")\n",
    "\n",
    "# Count n-gram matches\n",
    "def count_ngram_matches(ref, cand, n):\n",
    "    ref_ngrams = [tuple(ref[i:i+n]) for i in range(len(ref)-n+1)]\n",
    "    cand_ngrams = [tuple(cand[i:i+n]) for i in range(len(cand)-n+1)]\n",
    "    \n",
    "    ref_counts = Counter(ref_ngrams)\n",
    "    cand_counts = Counter(cand_ngrams)\n",
    "    \n",
    "    matches = sum((ref_counts & cand_counts).values())\n",
    "    total = len(cand_ngrams)\n",
    "    \n",
    "    return matches, total, matches/total if total > 0 else 0\n",
    "\n",
    "print(\"\\nn-gram precision:\")\n",
    "for n in range(1, 5):\n",
    "    matches, total, precision = count_ngram_matches(reference, candidate, n)\n",
    "    print(f\"  {n}-gram: {matches}/{total} = {precision:.1%}\")\n",
    "\n",
    "# Overall BLEU\n",
    "bleu = sentence_bleu([reference], candidate)\n",
    "print(f\"\\nOverall BLEU: {bleu:.3f}\")\n",
    "\n",
    "print(\"\\nWhat changed:\")\n",
    "print(\"  'quick' ‚Üí 'fast' (synonym, but BLEU doesn't know that!)\")\n",
    "print(\"  'jumps' ‚Üí 'leaps' (synonym, but BLEU penalizes it)\")\n",
    "print(\"\\nüí° BLEU limitation: Doesn't understand synonyms or meaning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ CHALLENGE: Test Your Own Translations!\n",
    "\n",
    "Want to see how BLEU scores different translations?\n",
    "\n",
    "**Try this:**\n",
    "1. Pick a simple sentence in another language you know\n",
    "2. Create 3-5 different English translations (exact, with synonyms, reordered, etc.)\n",
    "3. Use `sentence_bleu()` to score each one\n",
    "4. See how BLEU handles synonyms vs word order\n",
    "\n",
    "**Question:** Which matters more to BLEU - using exact words or getting the order right?\n",
    "\n",
    "**Hint:** Try \"The dog chases the cat\" vs \"The cat chases the dog\" vs \"A dog pursues a cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 3: ROUGE Score üìù\n",
    "*For summarization - did you include the important parts?*\n",
    "\n",
    "### What is it?\n",
    "**ROUGE** = Recall-Oriented Understudy for Gisting Evaluation (yeah, they really tried with that acronym)\n",
    "\n",
    "Unlike BLEU (precision), ROUGE focuses on **RECALL** - did you cover the key content?\n",
    "\n",
    "### The Difference\n",
    "- **BLEU asks:** \"Is everything you said correct?\" (precision)\n",
    "- **ROUGE asks:** \"Did you include all the important stuff?\" (recall)\n",
    "\n",
    "**What's Precision vs Recall again?**\n",
    "- **Precision**: Of what you said, how much was correct? (quality of output)\n",
    "- **Recall**: Of what should be said, how much did you include? (completeness)\n",
    "\n",
    "### The Metaphor\n",
    "You're summarizing a movie for a friend:\n",
    "\n",
    "**BLEU mindset:** \"Everything I said was accurate!\" (but you only mentioned one scene)  \n",
    "**ROUGE mindset:** \"Did I cover all the major plot points?\" (completeness matters!)\n",
    "\n",
    "### ROUGE Flavors\n",
    "- **ROUGE-1:** Word overlap (unigrams)\n",
    "- **ROUGE-2:** Phrase overlap (bigrams)  \n",
    "- **ROUGE-L:** Longest common **subsequence** (order-aware matching)\n",
    "\n",
    "**What's a \"subsequence\"?** Words that appear in the same order, but not necessarily consecutively. Example: In \"the quick brown fox\", \"the brown fox\" is a subsequence (skips \"quick\").\n",
    "\n",
    "Let's see it work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ROUGE SCORE EXAMPLES\n",
      "============================================================\n",
      "\n",
      "Reference summary:\n",
      "  'Machine learning models require evaluation metrics \n",
      "to measure their performance on test data.'\n",
      "\n",
      "Good (covers main points)\n",
      "  Generated: 'Machine learning models require evaluation metrics to measure performance.'\n",
      "  ROUGE-1: 0.818 (unigram overlap)\n",
      "  ROUGE-2: 0.700 (bigram overlap)\n",
      "  ROUGE-L: 0.818 (longest common subsequence)\n",
      "\n",
      "Okay (shorter but captures essence)\n",
      "  Generated: 'Models need metrics to evaluate performance on data.'\n",
      "  ROUGE-1: 0.667 (unigram overlap)\n",
      "  ROUGE-2: 0.211 (bigram overlap)\n",
      "  ROUGE-L: 0.571 (longest common subsequence)\n",
      "\n",
      "Bad (different topic)\n",
      "  Generated: 'Deep learning is a subset of machine learning.'\n",
      "  ROUGE-1: 0.190 (unigram overlap)\n",
      "  ROUGE-2: 0.105 (bigram overlap)\n",
      "  ROUGE-L: 0.190 (longest common subsequence)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ROUGE SCORE EXAMPLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Reference summary\n",
    "reference_summary = \"\"\"Machine learning models require evaluation metrics \n",
    "to measure their performance on test data.\"\"\"\n",
    "\n",
    "# Different quality summaries\n",
    "summaries = [\n",
    "    (\n",
    "        \"Machine learning models require evaluation metrics to measure performance.\",\n",
    "        \"Good (covers main points)\"\n",
    "    ),\n",
    "    (\n",
    "        \"Models need metrics to evaluate performance on data.\",\n",
    "        \"Okay (shorter but captures essence)\"\n",
    "    ),\n",
    "    (\n",
    "        \"Deep learning is a subset of machine learning.\",\n",
    "        \"Bad (different topic)\"\n",
    "    )\n",
    "]\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "print(f\"\\nReference summary:\")\n",
    "print(f\"  '{reference_summary.strip()}'\\n\")\n",
    "\n",
    "for summary, description in summaries:\n",
    "    scores = scorer.score(reference_summary, summary)\n",
    "    \n",
    "    print(f\"{description}\")\n",
    "    print(f\"  Generated: '{summary}'\")\n",
    "    print(f\"  ROUGE-1: {scores['rouge1'].fmeasure:.3f} (unigram overlap)\")\n",
    "    print(f\"  ROUGE-2: {scores['rouge2'].fmeasure:.3f} (bigram overlap)\")\n",
    "    print(f\"  ROUGE-L: {scores['rougeL'].fmeasure:.3f} (longest common subsequence)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 4: ROUGE Components Explained\n",
    "*Breaking down the ROUGE scores*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ROUGE BREAKDOWN\n",
      "============================================================\n",
      "Reference: 'the cat sat on the mat'\n",
      "Generated: 'the cat is on the mat'\n",
      "\n",
      "ROUGE-1 (unigram):\n",
      "  Overlapping words: {'on', 'mat', 'the', 'cat'}\n",
      "  Precision: 4/len(cand) = 0.833\n",
      "  Recall:    4/len(ref) = 0.833\n",
      "  F1:        0.833\n",
      "\n",
      "ROUGE-2 (bigram):\n",
      "  Reference bigrams: ['the cat', 'cat sat', 'sat on', 'on the', 'the mat']\n",
      "  Generated bigrams: ['the cat', 'cat is', 'is on', 'on the', 'the mat']\n",
      "  ROUGE-2 F1: 0.600\n",
      "\n",
      "üí° ROUGE focuses on RECALL (did you include the key info?)\n",
      "   BLEU focuses on PRECISION (is what you said accurate?)\n"
     ]
    }
   ],
   "source": [
    "reference = \"the cat sat on the mat\"\n",
    "candidate = \"the cat is on the mat\"\n",
    "\n",
    "scores = scorer.score(reference, candidate)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ROUGE BREAKDOWN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Reference: '{reference}'\")\n",
    "print(f\"Generated: '{candidate}'\")\n",
    "\n",
    "print(\"\\nROUGE-1 (unigram):\")\n",
    "ref_words = set(reference.split())\n",
    "cand_words = set(candidate.split())\n",
    "overlap = ref_words & cand_words\n",
    "print(f\"  Overlapping words: {overlap}\")\n",
    "print(f\"  Precision: {len(overlap)}/len(cand) = {scores['rouge1'].precision:.3f}\")\n",
    "print(f\"  Recall:    {len(overlap)}/len(ref) = {scores['rouge1'].recall:.3f}\")\n",
    "print(f\"  F1:        {scores['rouge1'].fmeasure:.3f}\")\n",
    "\n",
    "print(\"\\nROUGE-2 (bigram):\")\n",
    "ref_bigrams = [f\"{reference.split()[i]} {reference.split()[i+1]}\" \n",
    "               for i in range(len(reference.split())-1)]\n",
    "cand_bigrams = [f\"{candidate.split()[i]} {candidate.split()[i+1]}\" \n",
    "                for i in range(len(candidate.split())-1)]\n",
    "print(f\"  Reference bigrams: {ref_bigrams}\")\n",
    "print(f\"  Generated bigrams: {cand_bigrams}\")\n",
    "print(f\"  ROUGE-2 F1: {scores['rouge2'].fmeasure:.3f}\")\n",
    "\n",
    "print(\"\\nüí° ROUGE focuses on RECALL (did you include the key info?)\")\n",
    "print(\"   BLEU focuses on PRECISION (is what you said accurate?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 5: BLEU vs ROUGE Showdown ü•ä\n",
    "*When to use what (and why they both have limitations)*\n",
    "\n",
    "Let's test both on the same examples and see how they differ!\n",
    "\n",
    "### The Setup\n",
    "- **Reference:** \"The quick brown fox jumps over the lazy dog\"\n",
    "- **Test cases:** Perfect match, synonyms, missing words, incomplete\n",
    "\n",
    "### What We'll Learn\n",
    "- BLEU is harsh on synonyms (doesn't understand meaning)\n",
    "- ROUGE is more forgiving (cares about coverage)\n",
    "- Both miss semantic meaning (they're word-counters, not mind-readers)\n",
    "\n",
    "Let's visualize the difference..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BLEU vs ROUGE - WHEN TO USE WHAT\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† ANALYZING THE BAR CHART:\n",
      "============================================================\n",
      "\n",
      "üìä COMPARING THE BARS ACROSS 4 TEST CASES:\n",
      "\n",
      "1. PERFECT:\n",
      "   Test: 'The quick brown fox jumps over the lazy dog'\n",
      "   üîµ BLEU  (blue):  1.000\n",
      "   üî¥ ROUGE (red):   1.000\n",
      "   ‚ú® Both 1.0! Perfect match = perfect scores\n",
      "\n",
      "2. SYNONYMS:\n",
      "   Test: 'The fast brown fox leaps over the lazy dog'\n",
      "   üîµ BLEU  (blue):  0.369\n",
      "   üî¥ ROUGE (red):   0.778\n",
      "   ‚ö° BIG DIFFERENCE! BLEU harsh on synonyms, ROUGE more forgiving\n",
      "      ‚Üí BLEU: 'fast' ‚â† 'quick'? PENALIZED! (precision-focused)\n",
      "      ‚Üí ROUGE: 'fast' similar to 'quick'? More tolerant! (recall-focused)\n",
      "\n",
      "3. MISSING WORDS:\n",
      "   Test: 'The fox jumps over the dog'\n",
      "   üîµ BLEU  (blue):  0.341\n",
      "   üî¥ ROUGE (red):   0.800\n",
      "   üìâ ROUGE higher! Missing words hurt BLEU more (needs exact matches)\n",
      "      ‚Üí BLEU cares about ALL words matching exactly\n",
      "      ‚Üí ROUGE cares about covering KEY words (more forgiving)\n",
      "\n",
      "4. INCOMPLETE:\n",
      "   Test: 'The quick brown fox jumps over the lazy'\n",
      "   üîµ BLEU  (blue):  0.882\n",
      "   üî¥ ROUGE (red):   0.941\n",
      "   ‚ö†Ô∏è Both drop but BLEU drops MORE (strict about completeness)\n",
      "\n",
      "üí° THE BIG PICTURE:\n",
      "============================================================\n",
      "\n",
      "üìà Average scores (excluding perfect match):\n",
      "   BLEU:  0.531 (more strict)\n",
      "   ROUGE: 0.840 (more forgiving)\n",
      "\n",
      "üî• ROUGE is way more forgiving than BLEU!\n",
      "   ‚Üí BLEU: 'Did you use EXACT words?' (precision nerd)\n",
      "   ‚Üí ROUGE: 'Did you cover IMPORTANT stuff?' (chill about synonyms)\n",
      "\n",
      "üéØ WHEN TO USE WHAT:\n",
      "  üìò BLEU (skyblue bars):\n",
      "     ‚úì Precision-focused - penalizes wrong/extra words\n",
      "     ‚úì Strict about exact matches\n",
      "     ‚úì Use for: Translation (accuracy matters!)\n",
      "     ‚úó Harsh on synonyms (doesn't understand meaning)\n",
      "\n",
      "  üìï ROUGE (coral bars):\n",
      "     ‚úì Recall-focused - rewards covering key content\n",
      "     ‚úì More forgiving on wording\n",
      "     ‚úì Use for: Summarization (completeness matters!)\n",
      "     ‚ö° Can miss if you add wrong stuff (less strict)\n",
      "\n",
      "üíÄ BOTH HAVE LIMITATIONS:\n",
      "   ‚Üí They count words, they don't understand MEANING\n",
      "   ‚Üí 'quick' vs 'fast'? They think those are different words\n",
      "   ‚Üí But hey, they're fast and work well enough for most cases!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BLEU vs ROUGE - WHEN TO USE WHAT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test on same example\n",
    "reference_text = \"The quick brown fox jumps over the lazy dog\"\n",
    "ref_tokens = reference_text.lower().split()\n",
    "\n",
    "test_cases = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",  # Perfect\n",
    "    \"The fast brown fox leaps over the lazy dog\",   # Synonyms\n",
    "    \"The fox jumps over the dog\",                   # Missing words\n",
    "    \"The quick brown fox jumps over the lazy\",      # Incomplete\n",
    "]\n",
    "\n",
    "bleu_scores = []\n",
    "rouge_scores = []\n",
    "\n",
    "for test in test_cases:\n",
    "    # BLEU\n",
    "    bleu = sentence_bleu([ref_tokens], test.lower().split())\n",
    "    bleu_scores.append(bleu)\n",
    "    \n",
    "    # ROUGE\n",
    "    rouge = scorer.score(reference_text, test)['rouge1'].fmeasure\n",
    "    rouge_scores.append(rouge)\n",
    "\n",
    "# Plot comparison\n",
    "x = np.arange(len(test_cases))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar(x - width/2, bleu_scores, width, label='BLEU', color='skyblue')\n",
    "bars2 = ax.bar(x + width/2, rouge_scores, width, label='ROUGE-1', color='lightcoral')\n",
    "\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('BLEU vs ROUGE Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Perfect', 'Synonyms', 'Missing\\nwords', 'Incomplete'], fontsize=10)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.0)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüß† ANALYZING THE BAR CHART:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìä COMPARING THE BARS ACROSS 4 TEST CASES:\")\n",
    "\n",
    "for i, (test_case, bleu, rouge) in enumerate(zip(['Perfect', 'Synonyms', 'Missing words', 'Incomplete'], bleu_scores, rouge_scores)):\n",
    "    print(f\"\\n{i+1}. {test_case.upper()}:\")\n",
    "    print(f\"   Test: '{test_cases[i]}'\")\n",
    "    print(f\"   üîµ BLEU  (blue):  {bleu:.3f}\")\n",
    "    print(f\"   üî¥ ROUGE (red):   {rouge:.3f}\")\n",
    "    \n",
    "    # Analyze the difference\n",
    "    diff = abs(bleu - rouge)\n",
    "    if test_case == 'Perfect':\n",
    "        print(f\"   ‚ú® Both 1.0! Perfect match = perfect scores\")\n",
    "    elif test_case == 'Synonyms':\n",
    "        if bleu < 0.5 and rouge > 0.7:\n",
    "            print(f\"   ‚ö° BIG DIFFERENCE! BLEU harsh on synonyms, ROUGE more forgiving\")\n",
    "            print(f\"      ‚Üí BLEU: 'fast' ‚â† 'quick'? PENALIZED! (precision-focused)\")\n",
    "            print(f\"      ‚Üí ROUGE: 'fast' similar to 'quick'? More tolerant! (recall-focused)\")\n",
    "    elif test_case == 'Missing words':\n",
    "        if bleu < rouge:\n",
    "            print(f\"   üìâ ROUGE higher! Missing words hurt BLEU more (needs exact matches)\")\n",
    "            print(f\"      ‚Üí BLEU cares about ALL words matching exactly\")\n",
    "            print(f\"      ‚Üí ROUGE cares about covering KEY words (more forgiving)\")\n",
    "    elif test_case == 'Incomplete':\n",
    "        print(f\"   ‚ö†Ô∏è Both drop but BLEU drops MORE (strict about completeness)\")\n",
    "\n",
    "print(\"\\nüí° THE BIG PICTURE:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Overall comparison\n",
    "avg_bleu = np.mean(bleu_scores[1:])  # Skip perfect match\n",
    "avg_rouge = np.mean(rouge_scores[1:])\n",
    "\n",
    "print(f\"\\nüìà Average scores (excluding perfect match):\")\n",
    "print(f\"   BLEU:  {avg_bleu:.3f} (more strict)\")\n",
    "print(f\"   ROUGE: {avg_rouge:.3f} (more forgiving)\")\n",
    "\n",
    "if avg_rouge > avg_bleu * 1.3:\n",
    "    print(f\"\\nüî• ROUGE is way more forgiving than BLEU!\")\n",
    "    print(f\"   ‚Üí BLEU: 'Did you use EXACT words?' (precision nerd)\")\n",
    "    print(f\"   ‚Üí ROUGE: 'Did you cover IMPORTANT stuff?' (chill about synonyms)\")\n",
    "elif avg_bleu > avg_rouge:\n",
    "    print(f\"\\n‚ö° BLEU stricter than ROUGE in this case!\")\n",
    "else:\n",
    "    print(f\"\\nüëç Both metrics roughly agree\")\n",
    "\n",
    "print(\"\\nüéØ WHEN TO USE WHAT:\")\n",
    "print(\"  üìò BLEU (skyblue bars):\")\n",
    "print(\"     ‚úì Precision-focused - penalizes wrong/extra words\")\n",
    "print(\"     ‚úì Strict about exact matches\")\n",
    "print(\"     ‚úì Use for: Translation (accuracy matters!)\")\n",
    "print(\"     ‚úó Harsh on synonyms (doesn't understand meaning)\")\n",
    "\n",
    "print(\"\\n  üìï ROUGE (coral bars):\")\n",
    "print(\"     ‚úì Recall-focused - rewards covering key content\")\n",
    "print(\"     ‚úì More forgiving on wording\")\n",
    "print(\"     ‚úì Use for: Summarization (completeness matters!)\")\n",
    "print(\"     ‚ö° Can miss if you add wrong stuff (less strict)\")\n",
    "\n",
    "print(\"\\nüíÄ BOTH HAVE LIMITATIONS:\")\n",
    "print(\"   ‚Üí They count words, they don't understand MEANING\")\n",
    "print(\"   ‚Üí 'quick' vs 'fast'? They think those are different words\")\n",
    "print(\"   ‚Üí But hey, they're fast and work well enough for most cases!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 6: Real-World Summarization Example\n",
    "*See ROUGE grade different summary qualities*\n",
    "\n",
    "Here's a real article and summaries at different quality levels.\n",
    "\n",
    "### The Harsh Truth\n",
    "- **Good summary (ROUGE ~0.6):** Covers main points, good word overlap\n",
    "- **Too short (ROUGE ~0.1):** Misses key info, weak overlap\n",
    "- **Wrong focus (ROUGE ~0.2):** Talks about related stuff but misses the point\n",
    "\n",
    "ROUGE will roast bad summaries! Let's see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù REAL SUMMARIZATION EXAMPLE\n",
      "============================================================\n",
      "\n",
      "üìÑ Original article (58 words):\n",
      "Machine learning evaluation metrics are essential for understanding \n",
      "model performance. For classification tasks, we use accuracy, precision, recall, \n",
      "and F1-score. For regression, we use MAE, MSE, RMSE, and R-squared. Text generation \n",
      "tasks require special metrics like BLEU for translation and ROUGE for summarization. \n",
      "Each metric serves a specific purpose and choosing the right one depends on your task.\n",
      "\n",
      "‚úÖ Reference summary (21 words):\n",
      "ML metrics include classification metrics like accuracy and F1, \n",
      "regression metrics like RMSE, and text generation metrics like BLEU and ROUGE.\n",
      "\n",
      "============================================================\n",
      "EVALUATING GENERATED SUMMARIES\n",
      "============================================================\n",
      "\n",
      "GOOD summary (20 words):\n",
      "  Machine learning uses different metrics: classification uses accuracy \n",
      "    and F1, regression uses RMSE, and text generation uses BLEU and ROUGE.\n",
      "\n",
      "  üìä Scores:\n",
      "    ROUGE-1: 0.634 (word overlap)\n",
      "    ROUGE-2: 0.410 (phrase overlap)\n",
      "    ROUGE-L: 0.634 (longest match)\n",
      "\n",
      "TOO SHORT summary (8 words):\n",
      "  ML has many evaluation metrics for different tasks.\n",
      "\n",
      "  üìä Scores:\n",
      "    ROUGE-1: 0.138 (word overlap)\n",
      "    ROUGE-2: 0.000 (phrase overlap)\n",
      "    ROUGE-L: 0.138 (longest match)\n",
      "\n",
      "WRONG FOCUS summary (13 words):\n",
      "  Classification and regression are important types of \n",
      "    machine learning that require careful evaluation.\n",
      "\n",
      "  üìä Scores:\n",
      "    ROUGE-1: 0.176 (word overlap)\n",
      "    ROUGE-2: 0.000 (phrase overlap)\n",
      "    ROUGE-L: 0.176 (longest match)\n",
      "\n",
      "============================================================\n",
      "üß† LESSON COMPLETE - KEY TAKEAWAYS:\n",
      "============================================================\n",
      "\n",
      "1. BLEU SCORE (Translation)\n",
      "   ‚úì Precision-focused (is generated text accurate?)\n",
      "   ‚úì Counts n-gram matches\n",
      "   ‚úó Doesn't understand synonyms or meaning\n",
      "   ‚úì Use for: Machine translation\n",
      "\n",
      "2. ROUGE SCORE (Summarization)\n",
      "   ‚úì Recall-focused (does it cover key content?)\n",
      "   ‚úì ROUGE-1: Word overlap\n",
      "   ‚úì ROUGE-2: Phrase overlap\n",
      "   ‚úì ROUGE-L: Longest common sequence\n",
      "   ‚úì Use for: Summarization, captions\n",
      "\n",
      "3. WHEN TO USE WHAT\n",
      "   Translation ‚Üí BLEU (accuracy matters)\n",
      "   Summarization ‚Üí ROUGE (completeness matters)\n",
      "\n",
      "üéâ Great job learning text generation metrics!\n",
      "\n",
      "üöÄ Next up: Lesson 5 - ROC/AUC (Advanced Classification)!\n"
     ]
    }
   ],
   "source": [
    "print(\"üìù REAL SUMMARIZATION EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Long article\n",
    "article = \"\"\"Machine learning evaluation metrics are essential for understanding \n",
    "model performance. For classification tasks, we use accuracy, precision, recall, \n",
    "and F1-score. For regression, we use MAE, MSE, RMSE, and R-squared. Text generation \n",
    "tasks require special metrics like BLEU for translation and ROUGE for summarization. \n",
    "Each metric serves a specific purpose and choosing the right one depends on your task.\"\"\"\n",
    "\n",
    "# Reference summary\n",
    "reference_summary = \"\"\"ML metrics include classification metrics like accuracy and F1, \n",
    "regression metrics like RMSE, and text generation metrics like BLEU and ROUGE.\"\"\"\n",
    "\n",
    "# Generated summaries (different quality)\n",
    "generated_summaries = [\n",
    "    (\"Good\", \"\"\"Machine learning uses different metrics: classification uses accuracy \n",
    "    and F1, regression uses RMSE, and text generation uses BLEU and ROUGE.\"\"\"),\n",
    "    \n",
    "    (\"Too short\", \"ML has many evaluation metrics for different tasks.\"),\n",
    "    \n",
    "    (\"Wrong focus\", \"\"\"Classification and regression are important types of \n",
    "    machine learning that require careful evaluation.\"\"\"),\n",
    "]\n",
    "\n",
    "print(f\"\\nüìÑ Original article ({len(article.split())} words):\")\n",
    "print(article)\n",
    "print(f\"\\n‚úÖ Reference summary ({len(reference_summary.split())} words):\")\n",
    "print(reference_summary)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATING GENERATED SUMMARIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for quality, summary in generated_summaries:\n",
    "    scores = scorer.score(reference_summary, summary)\n",
    "    \n",
    "    print(f\"\\n{quality.upper()} summary ({len(summary.split())} words):\")\n",
    "    print(f\"  {summary.strip()}\")\n",
    "    print(f\"\\n  üìä Scores:\")\n",
    "    print(f\"    ROUGE-1: {scores['rouge1'].fmeasure:.3f} (word overlap)\")\n",
    "    print(f\"    ROUGE-2: {scores['rouge2'].fmeasure:.3f} (phrase overlap)\")\n",
    "    print(f\"    ROUGE-L: {scores['rougeL'].fmeasure:.3f} (longest match)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üß† LESSON COMPLETE - KEY TAKEAWAYS:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. BLEU SCORE (Translation)\")\n",
    "print(\"   ‚úì Precision-focused (is generated text accurate?)\")\n",
    "print(\"   ‚úì Counts n-gram matches\")\n",
    "print(\"   ‚úó Doesn't understand synonyms or meaning\")\n",
    "print(\"   ‚úì Use for: Machine translation\")\n",
    "print()\n",
    "print(\"2. ROUGE SCORE (Summarization)\")\n",
    "print(\"   ‚úì Recall-focused (does it cover key content?)\")\n",
    "print(\"   ‚úì ROUGE-1: Word overlap\")\n",
    "print(\"   ‚úì ROUGE-2: Phrase overlap\")\n",
    "print(\"   ‚úì ROUGE-L: Longest common sequence\")\n",
    "print(\"   ‚úì Use for: Summarization, captions\")\n",
    "print()\n",
    "print(\"3. WHEN TO USE WHAT\")\n",
    "print(\"   Translation ‚Üí BLEU (accuracy matters)\")\n",
    "print(\"   Summarization ‚Üí ROUGE (completeness matters)\")\n",
    "print()\n",
    "print(\"üéâ Great job learning text generation metrics!\")\n",
    "print(\"\\nüöÄ Next up: Lesson 5 - ROC/AUC (Advanced Classification)!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
